{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59826bf-a5a5-4233-a8f9-b1c4db7216ee",
   "metadata": {},
   "source": [
    "# 17.2 Zadanie Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b8d9c-0992-4c10-8d19-b9a4e0ecce6b",
   "metadata": {},
   "source": [
    "#### Import niezbednych bibliotek i paczek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e36c2c-92e1-495a-8037-a78d9fd1df6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\piotr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\piotr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\piotr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import itertools\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70aed96-f2d7-406e-a8d8-22eb620eb096",
   "metadata": {},
   "source": [
    "#### Definicje wszystkich funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f16a14a-e809-4c3c-818f-130a283dc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncation(text):\n",
    "    cleaned = ''.join([word for word in text if word not in string.punctuation])\n",
    "    return cleaned\n",
    "def tokenize(text):\n",
    "    # Usunięcie wielkich liter\n",
    "    clean_text = text.lower()\n",
    "    # Tokenizacja\n",
    "    tokenized_text = nltk.word_tokenize(clean_text)\n",
    "    return tokenized_text\n",
    "def remove_stopwords(text):\n",
    "    without_stopwords = [word for word in text if word not in stopwords]\n",
    "    return without_stopwords\n",
    "def stemming(text):\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    return stemmed_words\n",
    "def lemmatizing(text):\n",
    "    lemmatized_words = [lemmater.lemmatize(word) for word in text]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d49463-97b5-4112-8a80-573296373501",
   "metadata": {},
   "source": [
    "#### Import pliku z danymi i jego formatowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169c218d-ef76-44bf-bed1-f22d19d6b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piotr\\AppData\\Local\\Temp\\ipykernel_23936\\1552169415.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n"
     ]
    }
   ],
   "source": [
    "spam_dataset = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\", usecols=[0, 1], names=['Spam', 'Text'],\n",
    "                           skiprows=1)\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05288c2-f9c6-4320-961c-1cb3eb919af2",
   "metadata": {},
   "source": [
    "#### Obróbka danych - czyszczenie, tokenizacja, usuwanie stop words, Stemming, Lametyzcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f698ae3-42e2-4ccf-a164-d3ac44bc32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(lambda x: remove_puncation(x))\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(lambda x: tokenize(x))\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(lambda x: remove_stopwords(x))\n",
    "stemmer = nltk.PorterStemmer()\n",
    "spam_dataset['Stemmed_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: stemming(x))\n",
    "lemmater = nltk.WordNetLemmatizer()\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458d99e-b0de-437a-b42c-a6414ae9b14d",
   "metadata": {},
   "source": [
    "#### Rozdzielenie na X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c275ce57-6a22-493c-9fbb-f4ad6a90c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x))\n",
    "y = spam_dataset['Spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12280cfa-33f7-4136-a15f-a3d244922275",
   "metadata": {},
   "source": [
    "#### Rozdzielenie danych na zbiory treningowe oraz testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b20a55a-639a-47e0-9ce1-ea71bd47ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65101b7d-edba-4e99-9369-686262e349fd",
   "metadata": {},
   "source": [
    "## Wektoryzacja TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdf822-fcbe-4b43-90be-d71ff4277c4d",
   "metadata": {},
   "source": [
    "#### Wykonanie wektoryzacji TfidfVectorizer dla danych testowych i treningowych, następnie wyszkolenie nmmodelu RandomForestClassifier dla X treningowych i odczytwanie wyniku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6133f437-2416-4740-9ffe-65da27cf82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość Score dla RandomForestCalssifier, przy TfidfVectorizer: 0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "clf_tfidf = RandomForestClassifier()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "print(\"Wartość Score dla RandomForestCalssifier, przy TfidfVectorizer:\",clf_tfidf.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02682cbd-e1d7-4bd1-b07d-e0ceac11216f",
   "metadata": {},
   "source": [
    "#### Określenie indeksu słów które miały ważność większą niż 0.001 dla RandomForestClassifier, a następnie przekazanie do dalszej analizy matryc zawierających tylko te najważniejsze słowa, zarówno dla danych treningowych jak i testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43426e82-6fc3-4136-9a37-c4502bc899e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = (np.where(clf_tfidf.feature_importances_ > 0.001))[0].tolist()\n",
    "X_train_imp = X_train_tfidf[:,important_features]\n",
    "X_test_imp = X_test_tfidf[:,important_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e588cc4-df82-4434-947d-5294dd6bf302",
   "metadata": {},
   "source": [
    "#### Wyszkolenie nowego RandomForestClassifier z wykorzystaniem Grid Search dla słów z ważnością wiekszą niż 0.001, odczytanie wyniku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a204271-22d7-465f-a28b-022d4b4919c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Best hyperparameter: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Grid search for RandomForestClassifier Score Test (TfidfVectorizer): 0.979372197309417\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier( n_jobs=-1)\n",
    "params_rf = {'max_depth': [ None, 15],\n",
    "             'min_samples_leaf': [1, 3],\n",
    "             'n_estimators': [ 50, 100, 150 ],\n",
    "             'min_samples_split': [2, 3, 5]}\n",
    "\n",
    "rf_gridsearch = GridSearchCV(random_forest,\n",
    "                             params_rf,\n",
    "                             scoring='f1_micro',\n",
    "                             cv=5,\n",
    "                             verbose=10, n_jobs=-1)\n",
    "rf_gridsearch.fit(X_train_imp, y_train)\n",
    "print('\\nBest hyperparameter:', rf_gridsearch.best_params_)\n",
    "model = rf_gridsearch.best_estimator_\n",
    "model.fit(X_train_imp, y_train)\n",
    "print(\"Grid search for RandomForestClassifier Score Test (TfidfVectorizer):\", model.score(X_test_imp, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237999c-e6e9-42fb-87a5-10023a8605ca",
   "metadata": {},
   "source": [
    "## Wektoryzacja CountVectorizer - metodologia taka sama jak poprzednio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dcb0ff-6c6c-4eed-afd4-a610248fdfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość Score dla RandomForestCalssifier, przy CountVectorizer: 0.9713004484304932\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "X_train_count = count.fit_transform(X_train)\n",
    "X_test_count = count.transform(X_test)\n",
    "clf_count = RandomForestClassifier()\n",
    "clf_count.fit(X_train_count, y_train)\n",
    "print(\"Wartość Score dla RandomForestCalssifier, przy CountVectorizer:\",clf_count.score(X_test_count, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d48122d-95ab-4e61-8f6c-d66aa1e0aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_count = (np.where(clf_tfidf.feature_importances_ > 0.001))[0].tolist()\n",
    "X_train_imp_count = X_train_tfidf[:,important_features_count]\n",
    "X_test_imp_count = X_test_tfidf[:,important_features_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8e3f2c-3a6e-4f1f-a1e0-a680aa9a96ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Best hyperparameter: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Grid search for RandomForestClassifier Score Test (CountVectorizer): 0.9766816143497757\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier( n_jobs=-1)\n",
    "params_rf = {'max_depth': [ None, 15 ],\n",
    "             'min_samples_leaf': [1, 3],\n",
    "             'n_estimators': [ 50, 100, 150 ],\n",
    "             'min_samples_split': [2, 3, 5]}\n",
    "\n",
    "rf_gridsearch = GridSearchCV(random_forest,\n",
    "                             params_rf,\n",
    "                             scoring='f1_micro',\n",
    "                             cv=5,\n",
    "                             verbose=10, n_jobs=-1)\n",
    "rf_gridsearch.fit(X_train_imp_count, y_train)\n",
    "print('\\nBest hyperparameter:', rf_gridsearch.best_params_)\n",
    "model = rf_gridsearch.best_estimator_\n",
    "model.fit(X_train_imp_count, y_train)\n",
    "print(\"Grid search for RandomForestClassifier Score Test (CountVectorizer):\", model.score(X_test_imp_count, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892411b0-4d90-4719-ad8e-ef1e7fa99354",
   "metadata": {},
   "source": [
    "#### Dzięki użyciu słow które miały wazność wiekszą niż 0.001 (dla pierwszego użycia RandomForestClassifier) Udało się poprwić wynik Score klasyfikacji  RandomForestClassifier zarowno dla  CountVectorizer jak i dla TfidfVectorizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
